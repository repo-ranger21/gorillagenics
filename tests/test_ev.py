"""""""Tests for EV calculation module.\n\nimport pytest\nimport pandas as pd\nimport numpy as np\nfrom src.gorillagenics.ev import (\n    calculate_ev,\n    calculate_win_probability,\n    calculate_parlay_probability,\n    evaluate_pick_ev,\n    batch_ev_calculation\n)\n\n\nclass TestEVCalculations:  # Test cases for EV calculations.\n    def test_calculate_ev_positive(self):  # Test EV calculation for positive expected value.\n        result = calculate_ev(pick_odds=2.0, win_probability=0.6, stake=100)\n        assert result['ev'] == pytest.approx(20.0)  # (0.6 * 2.0 * 100) - 100\n        assert result['ev_percentage'] == pytest.approx(20.0)\n        assert result['expected_return'] == pytest.approx(120.0)\n    def test_calculate_ev_negative(self):  # Test EV calculation for negative expected value.\n        result = calculate_ev(pick_odds=1.5, win_probability=0.4, stake=100)\n        assert result['ev'] == pytest.approx(-40.0)  # (0.4 * 1.5 * 100) - 100\n        assert result['ev_percentage'] == pytest.approx(-40.0)\n    def test_calculate_win_probability_neutral(self):  # Test win probability calculation for neutral game script.\n        player_stats = {'hit_rate': 0.5, 'avg_points': 15.0, 'consistency': 0.7}\n        prob = calculate_win_probability(player_stats, "neutral")\n        assert 0.0 <= prob <= 1.0\n        assert prob == pytest.approx(0.5)  # Should equal base hit rate for neutral script\n    def test_calculate_win_probability_shootout(self):  # Test win probability calculation for shootout game script.\n        player_stats = {'hit_rate': 0.5, 'avg_points': 15.0, 'consistency': 0.7}\n        prob = calculate_win_probability(player_stats, "shootout")\n        assert prob > 0.5  # Should be higher than neutral\n        assert prob == pytest.approx(0.575)  # 0.5 * 1.15\n    def test_calculate_parlay_probability_independent(self):  # Test parlay probability for independent events.\n        probabilities = [0.6, 0.5, 0.7]\n        result = calculate_parlay_probability(probabilities)\n        expected = 0.6 * 0.5 * 0.7\n        assert result == pytest.approx(expected)\n    def test_evaluate_pick_ev_complete(self):  # Test complete pick evaluation.\n        pick_data = {\n            'historical_hit_rate': 0.6,\n            'avg_fantasy_points': 18.0,\n            'consistency_score': 0.75\n        }\n        result = evaluate_pick_ev(pick_data, 1.91, {'script': 'neutral'})\n        assert 'ev_percentage' in result\n        assert 'win_probability' in result\n        assert 'value_rating' in result\n        assert result['win_probability'] == pytest.approx(0.6)\n    def test_batch_ev_calculation(self):  # Test batch EV calculation on DataFrame.\n        data = {\n            'player_name': ['Player A', 'Player B'],\n            'odds': [1.91, 2.0],\n            'historical_hit_rate': [0.6, 0.5],\n            'avg_fantasy_points': [18.0, 15.0],\n            'consistency_score': [0.75, 0.65]\n        }\n        df = pd.DataFrame(data)\n        result = batch_ev_calculation(df)\n        assert len(result) == 2\n        assert 'ev_ev_percentage' in result.columns\n        assert 'ev_win_probability' in result.columns\n\n\n@pytest.fixture\ndef sample_picks_data():  # Sample picks data for testing.\n    return pd.DataFrame({\n        'player_name': ['Josh Allen', 'Stefon Diggs', 'Travis Kelce'],\n        'position': ['QB', 'WR', 'TE'],\n        'team': ['BUF', 'BUF', 'KC'],\n        'prop_type': ['Passing Yards', 'Receiving Yards', 'Receiving Yards'],\n        'line': [275.5, 75.5, 65.5],\n        'odds': [1.91, 1.87, 1.95],\n        'historical_hit_rate': [0.65, 0.58, 0.62],\n        'avg_fantasy_points': [22.5, 18.2, 16.8],\n        'consistency_score': [0.75, 0.68, 0.72]\n    })\n\ndef test_batch_calculation_with_sample_data(sample_picks_data):  # Test batch calculation with realistic sample data.\n    result = batch_ev_calculation(sample_picks_data)\n    assert len(result) == 3\n    assert all(col.startswith('ev_') for col in result.columns if col not in sample_picks_data.columns)\n    # Check that all EV calculations are reasonable\n    assert all(result['ev_win_probability'] >= 0)\n    assert all(result['ev_win_probability'] <= 1)\n